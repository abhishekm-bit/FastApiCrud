# ğŸš€ Training Syllabus Generation â€“ EdTech (RAG Based)

AI-powered Training Syllabus Generator for EdTech domain using
Web-Augmented Generation (RAG) architecture.

This project scrapes real course data from URLs, converts it into embeddings, stores it in FAISS, retrieves relevant content, and generates professional syllabi using Gemini AI.


## ğŸ“Œ Project Details

Domain: EdTech
Title: Training Syllabus Generation
Architecture: RAG (Retrieval Augmented Generation)
Backend Weightage: 70%
Frontend Weightage: 30%


# ğŸ¯ Objective

To generate industry-aligned training syllabus by combining:
Real-world web data
Vector search (FAISS)
Gemini AI generation
Modern FastAPI backend
React + MUI frontend



# ğŸ— Folder Structure
```
9-01-2026/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
|        â”œâ”€â”€auth.py
|        â”œâ”€â”€syllabus.py  
â”‚   â”œâ”€â”€ db/
|        â”œâ”€â”€mongo.py
|        â”œâ”€â”€vector_db.py  
â”‚   â”œâ”€â”€ models/
|        â”œâ”€â”€gemini_Model_Lists.py
|        â”œâ”€â”€schemas.py  
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â”œâ”€â”€ gemini.py
â”‚   â”‚   â”œâ”€â”€ rag.py
â”‚   â”‚   â”œâ”€â”€ scraper.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ node_modules/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ SyllabusForm.jsx
â”‚   â”‚   â”œâ”€â”€ redux/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.js
â”‚   â”‚   â”‚   â””â”€â”€ store.js
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚
â””â”€â”€ README.md
```

# âš™ Tech Stack
## Backend

FastAPI
BeautifulSoup
FAISS
Gemini API
MongoDB

## Frontend
React
Material UI (MUI)
RTK Query
Redux Toolkit

# ğŸ”„ Workflow (RAG Pipeline)
```
User enters URL
        â†“
Web scraping (BeautifulSoup)
        â†“
(Optional) Chunking
        â†“
Convert text â†’ embeddings
        â†“
Normalize embeddings
        â†“
Store vectors in FAISS
        â†“
User query â†’ embedding
        â†“
Normalize query vector
        â†“
Similarity search in FAISS
        â†“
Relevant context retrieved
        â†“
Context + prompt â†’ Gemini AI
        â†“
Syllabus generated
        â†“
Response shown in frontend

```

# ğŸ§  Why URL is Used?

Provides real-world syllabus data
Improves accuracy
Makes output industry-relevant
Enables Web-Augmented Generation

# ğŸ›  Backend Setup

1 Create Virtual Environment

``` bash
python -m venv venv
venv\Scripts\activate
```

2 Create Virtual Environment
``` bash
python -m venv venv
venv\Scripts\activate
```

3ï¸ Create .env / config
In backend/config.py
```bash
GEMINI_API_KEY="YOUR_API_KEY"
MONGO_URL="mongodb://localhost:27017"
```

4ï¸ Run Backend
``` bash
uvicorn main:app --reload
```

Backend runs at:
``` bash
http://127.0.0.1:8000
```

Swagger:
``` bash
http://127.0.0.1:8000/docs
```

# ğŸ¨ Frontend Setup
1ï¸ Install Dependencies
``` bash
cd frontend
npm install
```

2ï¸ Create .env
```bash
REACT_APP_API_URL=http://127.0.0.1:8000
```

3ï¸ Start Frontend
```bash
npm start
```

Frontend runs at:
```bash
http://localhost:3000
```

# ğŸ”¥ API Endpoint

Generate syllabus

``` bash
POST /api/generate
```
Payload

```
{
  "url": "https://example.com/course",
  "course": "MERN Stack",
  "level": "Beginner",
  "duration": "1 Month"
}
```

# ğŸ§ª Testing & Coverage Report

This project uses PyTest for backend testing and pytest-cov for coverage reporting.

## âœ… What is tested?
We currently test backend functionality only, including:
API endpoint working (/api/generate)
Web scraping logic
Embedding generation
FAISS vector storage & retrieval
RAG pipeline execution


# ğŸ“‚ Test Files Location
```
backend/tests/
â”œâ”€â”€ test_api.py
â”œâ”€â”€ test_scraper.py
â”œâ”€â”€ test_embeddings.py
â”œâ”€â”€ test_rag.py

```
# â–¶ Run Tests
``` bash
pytest
```

# ğŸ“Š Generate Coverage Report (Terminal)
```bash
pytest --cov=. --cov-report=term
```
# ğŸŒ Generate HTML Coverage Report
``` bash 
pytest --cov=. --cov-report=html
```
After running this command:
``` bash
backend/htmlcov/index.html
```
Open index.html in browser to view:

âœ” File-wise coverage
âœ” Percentage covered
âœ” Highlighted lines (green/red)

index.html is the official coverage report.

# ğŸ“ Save Coverage Output
``` bash
pytest --cov=. --cov-report=term > coverage.txt
```

```
ğŸ¯ Summary
Backend logic is fully tested
API integration tested
Coverage report generated using pytest-cov
HTML report available at htmlcov/index.html
```

# ğŸ† Tools Used
```
PyTest
pytest-cov
FastAPI TestClient
```

# ğŸ—ƒ FAISS Storage

Stores embeddings in-memory
Used for similarity search
Can be persisted if needed

# ğŸ“ˆ Features

âœ” RAG Architecture
âœ” Web scraping
âœ” Vector similarity search
âœ” Gemini prompt engineering
âœ” MongoDB logging
âœ” RTK Query
âœ” Form validation
âœ” Clean UI.



